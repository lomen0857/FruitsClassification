{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import shap\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "\n",
    "\n",
    "from numpy import argmax\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "#tensorflow2系の場合、以下はエラー・・・\n",
    "#from tensorflow.Keras.callbacks import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "font = {'family' : 'meiryo'}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand2square(pil_img, background_color):\n",
    "    width, height = pil_img.size\n",
    "    if width == height:\n",
    "        return pil_img\n",
    "    elif width > height:\n",
    "        result = Image.new(pil_img.mode, (width, width), background_color)\n",
    "        result.paste(pil_img, (0, (width - height) // 2))\n",
    "        return result\n",
    "    else:\n",
    "        result = Image.new(pil_img.mode, (height, height), background_color)\n",
    "        result.paste(pil_img, ((height - width) // 2, 0))\n",
    "        return result\n",
    "\n",
    "def mask_circle_solid(pil_img, background_color, blur_radius):\n",
    "    background = Image.new(pil_img.mode, pil_img.size, background_color)\n",
    "    mask = Image.new(\"L\", pil_img.size, 0)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "    draw.ellipse((blur_radius, blur_radius, pil_img.size[0] - blur_radius, pil_img.size[1] - blur_radius), fill=255)\n",
    "    \n",
    "    return Image.composite(pil_img, background, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=128\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for variety_id in [dir_name[-2:] for dir_name in glob.glob(\"./images/*\")]:\n",
    "    for img_file_path in glob.glob(\"./images/\" + variety_id + \"/*\"):\n",
    "        image = Image.open(img_file_path)\n",
    "        image = image.convert(\"RGB\")\n",
    "        \n",
    "        #縦横比を保ったまま正方形にする\n",
    "        #image = expand2square(image, (0, 0, 0)).resize((image_size, image_size), Image.LANCZOS)\n",
    "        \n",
    "        image = image.resize((image_size, image_size))\n",
    "        \n",
    "        #円で切り取る\n",
    "        image = mask_circle_solid(image, (0, 0, 0), -5)\n",
    "        \n",
    "        X.append(np.array(image))\n",
    "        Y.append(variety_id)\n",
    "del image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    plt.imshow(X[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_variety = [int(i) - 1 for i in Y]\n",
    "output_num = len(set(Y_variety))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, kernel_size = 3, activation=\"relu\", input_shape=(image_size,image_size,3)))\n",
    "    model.add(Conv2D(16, kernel_size = 3, activation=\"relu\"))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size = 3, activation=\"relu\"))\n",
    "    model.add(Conv2D(32, kernel_size = 3, activation=\"relu\"))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size = 3, activation=\"relu\"))\n",
    "    model.add(Conv2D(64, kernel_size = 3, activation=\"relu\"))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(output_num, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_vgg():\n",
    "    #base_model=VGG16(weights='imagenet',include_top=False,\n",
    "    #             input_tensor=Input(shape=(image_size,image_size,3)))\n",
    "    base_model=VGG16(weights='imagenet',include_top=False,\n",
    "                 input_shape=(image_size,image_size,3))\n",
    "    x = base_model.output\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    prediction = Dense(output_num, activation='softmax')(x)\n",
    "\n",
    "    for layer in base_model.layers[:15]:\n",
    "        layer.trainable=False\n",
    "    \n",
    "    return Model(inputs=base_model.input,outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(X, Y):\n",
    "    \n",
    "    X = np.array(X).astype(\"float32\") / 255\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(X,Y)):\n",
    "        \n",
    "        print('#'*25)\n",
    "        print('### FOLD %i'%(fold+1))\n",
    "        print('#'*25)\n",
    "        \n",
    "        ce_ohe = ce.OneHotEncoder(handle_unknown='impute')\n",
    "        Y = np.array(ce_ohe.fit_transform(Y))\n",
    "        \n",
    "        X_train = X[train_index]\n",
    "        X_valid = X[test_index]\n",
    "        Y_train = Y[train_index]\n",
    "        Y_valid = Y[test_index]\n",
    "    \n",
    "        datagen = ImageDataGenerator(\n",
    "                featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                samplewise_center=False,  # set each sample mean to 0\n",
    "                featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                samplewise_std_normalization=False,  # divide each input by its std\n",
    "                zca_whitening=False,  # apply ZCA whitening\n",
    "                rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                zoom_range = 0.05, # Randomly zoom image \n",
    "                width_shift_range=0.05,  # randomly shift images horizontally (fraction of total width)\n",
    "                height_shift_range=0.05,  # randomly shift images vertically (fraction of total height)\n",
    "                horizontal_flip=True,  # randomly flip images\n",
    "                vertical_flip=True)  # randomly flip images\n",
    "\n",
    "        datagen.fit(X_train)\n",
    "\n",
    "        #sess = InteractiveSession()\n",
    "\n",
    "        model = create_model_vgg()\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=\"rmsprop\", metrics=['accuracy'])\n",
    "        model.summary()\n",
    "\n",
    "        #callbacks = [ReduceLROnPlateau(monitor='loss', patience=4, verbose=1, factor=0.6),\n",
    "        #         EarlyStopping(monitor='loss', patience=10)]\n",
    "\n",
    "        #hist = model.fit(X_train, y_train, epochs=10, batch_size=64,verbose=1,callbacks=callbacks)\n",
    "        learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                                patience=4, \n",
    "                                                verbose=1, \n",
    "                                                factor=0.6, \n",
    "                                                min_lr=0.00001)\n",
    "        \n",
    "        hist = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=64),\n",
    "                                  epochs = 50, validation_data = (X_valid,Y_valid),\n",
    "                                  verbose = 2, steps_per_epoch=X_train.shape[0] // 64\n",
    "                                  , callbacks=[learning_rate_reduction])\n",
    "\n",
    "        model.save(\"model/model_\" + str(fold) + \".h5\")\n",
    "        #hist.save(\"model/hist_\" + str(fold) + \".h5\")\n",
    "\n",
    "        pred = model.predict(X_valid)\n",
    "        Y_pred_classes = argmax(pred, axis=1)\n",
    "        Y_true = argmax(Y_valid, axis=1)\n",
    "        ACC_pred = accuracy_score(Y_pred_classes, Y_true)\n",
    "\n",
    "        fig = plt.figure(figsize=(12, 16))\n",
    "        fig.subplots_adjust(wspace=0.5)\n",
    "        fig.suptitle(\"hist\", fontsize=20)\n",
    "\n",
    "        ax1 = fig.add_subplot(211,\n",
    "                              title=\"Loss:\",\n",
    "                              ylabel=\"Loss\",\n",
    "                              xlabel=\"Epoch\")\n",
    "        ax1.plot(hist.history[\"loss\"])\n",
    "        ax1.legend([\"Train\", \"Test\"], loc=\"upper left\")\n",
    "\n",
    "        ax2 = fig.add_subplot(212,\n",
    "                              title=\"val Acc:\",\n",
    "                              ylabel=\"val Acc\",\n",
    "                              xlabel=\"Epoch\")\n",
    "        ax2.plot(hist.history['val_accuracy'])\n",
    "        ax2.legend([\"Train\", \"Test\"], loc=\"upper left\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        #with tf.Session() as sess:\n",
    "        #     sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        Y_pred_classes = np.argmax(pred,axis = 1) \n",
    "        \n",
    "        errors = (Y_pred_classes - Y_true != 0)\n",
    "        Y_pred_classes_errors = Y_pred_classes[errors]\n",
    "        Y_pred_errors = pred[errors]\n",
    "        Y_true_errors = Y_true[errors]\n",
    "        X_val_errors = X_valid[errors]\n",
    "\n",
    "        def display_errors(errors_index, img_errors, pred_errors, obs_errors):\n",
    "            n = 0\n",
    "            nrows = 2\n",
    "            ncols = 5\n",
    "            fig, ax = plt.subplots(nrows, ncols, sharex=True, sharey=True, figsize=(20, 8))\n",
    "            for row in range(nrows):\n",
    "                for col in range(ncols):\n",
    "                    error = errors_index[n]\n",
    "                    ax[row, col].imshow((img_errors[error]).reshape((image_size, image_size,3)))\n",
    "                    ax[row, col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error], obs_errors[error]))\n",
    "                    n += 1\n",
    "            plt.show()\n",
    "\n",
    "        Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n",
    "        true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n",
    "        delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n",
    "        sorted_dela_errors = np.argsort(delta_pred_true_errors)\n",
    "        most_important_errors = sorted_dela_errors[-10:]\n",
    "\n",
    "        display_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)\n",
    "        \n",
    "        #explainer = shap.DeepExplainer(model, (X_train[0:100]))\n",
    "        #for i in most_important_errors:\n",
    "        #    shap_values = explainer.shap_values(X_val_errors[[i]])\n",
    "        #    index_names = np.array([str(x) + \"\\n\" + '{:>7.3%}'.format(Y_pred_errors[i][x]) for x in range(output_num)]).reshape(1,output_num)\n",
    "        #    print(\"Predicted label :{}\\nTrue label :{}\".format(Y_pred_classes_errors[i],Y_true_errors[i]))\n",
    "        #    \n",
    "        #    shap.image_plot(shap_values, X_val_errors[[i]] ,index_names)\n",
    "        #    plt.gcf().set_size_inches(20, 20)\n",
    "\n",
    "        print('>>>> FOLD %i val Acc ='%(fold+1), ACC_pred)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "test_path = \"./fruits-360/Test/\"\n",
    "Y_test = []\n",
    "\n",
    "for dir_name in os.listdir(test_path):\n",
    "    if \"Apple\" in dir_name:\n",
    "        for file_name in os.listdir(test_path + dir_name):\n",
    "            Y_test.append(dir_name)\n",
    "            file_list.append(test_path + dir_name + \"/\" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=80\n",
    "X_test = []\n",
    "\n",
    "for image_path in file_list:\n",
    "    #画像ファイル取得\n",
    "    img_file = glob.glob(image_path)\n",
    "    if not img_file:\n",
    "        print(image_path)\n",
    "        continue\n",
    "    image = Image.open(img_file[0])\n",
    "    image = image.convert(\"RGB\")\n",
    "    image = image.resize((image_size, image_size))\n",
    "    X_test.append(np.array(image))\n",
    "    \n",
    "del image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test).astype(\"float32\") / 255\n",
    "ce_ohe = ce.OneHotEncoder(handle_unknown='impute')\n",
    "Y_test = np.array(ce_ohe.fit_transform(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.zeros((len(X_test),13))\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    model = pickle.load(open(\"model/model_\"+ str(i) +\".sav\",\"rb\"))\n",
    "    temp = model.predict(X_test)\n",
    "    pred += temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = argmax(pred, axis=1)\n",
    "Y_true = argmax(Y_test, axis=1)\n",
    "ACC_pred = accuracy_score(Y_pred, Y_true)\n",
    "print('>>>> val Acc =', ACC_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_pred_classes = np.argmax(pred,axis = 1) \n",
    "#Y_true = np.argmax(Y_val,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = (Y_pred - Y_true != 0)\n",
    "\n",
    "Y_pred_classes_errors = Y_pred[errors]\n",
    "Y_pred_errors = pred[errors]\n",
    "Y_true_errors = Y_true[errors]\n",
    "X_val_errors = X_test[errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n",
    "    \"\"\" This function shows 10 images with their predicted and real labels\"\"\"\n",
    "    n = 0\n",
    "    nrows = 2\n",
    "    ncols = 5\n",
    "    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True,figsize=(20, 8))\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error = errors_index[n]\n",
    "            ax[row,col].imshow((img_errors[error]).reshape((image_size,image_size,3)))\n",
    "            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n",
    "            n += 1\n",
    "    plt.show()\n",
    "    \n",
    "Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n",
    "true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n",
    "delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n",
    "sorted_dela_errors = np.argsort(delta_pred_true_errors)\n",
    "most_important_errors = sorted_dela_errors[-10:]\n",
    "\n",
    "display_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When describing Deep Learning, we use DeepExplainer.\n",
    "explainer = shap.DeepExplainer(model, (np.array(X)[0:100]))\n",
    "\n",
    "#Check out the 10 data that the model has mistakenly predicted.\n",
    "for i in most_important_errors:\n",
    "    \n",
    "    #Calculates the SHAP value.\n",
    "    shap_values = explainer.shap_values(X_val_errors[[i]])\n",
    "    \n",
    "    #The following two lines are extras. It works even if you turn it off.\n",
    "    index_names = np.array([str(x) + \"\\n\" + '{:>7.3%}'.format(Y_pred_errors[i][x]) for x in range(10)]).reshape(1,10)\n",
    "    print(\"Predicted label :{}\\nTrue label :{}\".format(Y_pred_classes_errors[i],Y_true_errors[i]))\n",
    "    \n",
    "    #Displays the results.\n",
    "    shap.image_plot(shap_values, X_val_errors[[i]] ,index_names ,show=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
